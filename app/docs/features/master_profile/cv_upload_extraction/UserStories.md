# User Stories - CV Upload & Extraction Feature

**Version:** 1.0
**Date:** October 6, 2025
**Status:** Ready for Sprint Planning (when feature approved)

---

## Definition of Ready (DoR)

A user story is ready for sprint when:
- [ ] Acceptance criteria complete and testable
- [ ] Dependencies identified and unblocked
- [ ] Story points estimated (Fibonacci: 1,2,3,5,8,13)
- [ ] Technical approach documented
- [ ] UI mockups attached (if UI work)
- [ ] Database schema changes identified
- [ ] Security implications reviewed
- [ ] **For Story 3 (AI Extraction):** Sprint 0 spike completed with go/no-go decision

---

## Definition of Done (DoD)

A user story is done when:
- [ ] Code complete and self-reviewed
- [ ] Unit tests written (>80% coverage for new code)
- [ ] Integration/E2E tests for critical paths
- [ ] Manual testing completed with checklist
- [ ] RLS policies tested (no unauthorized access)
- [ ] Accessibility verified (axe DevTools scan passed)
- [ ] Error messages are user-friendly
- [ ] Documentation updated (inline comments, README)
- [ ] Mobile responsive (tested on 3 viewport sizes)
- [ ] Product owner accepted

---

## Story Estimation Scale

**Story Points (Fibonacci Scale):**
- **1 point:** ~1-2 hours (trivial change, e.g., add button)
- **2 points:** ~2-4 hours (small feature, e.g., simple modal)
- **3 points:** ~4-6 hours (medium feature, e.g., file upload UI)
- **5 points:** ~6-10 hours (large feature, e.g., form integration)
- **8 points:** ~10-16 hours (very large, e.g., AI extraction backend)
- **13 points:** Too large, must be split into smaller stories

---

## Sprint 0: Spike & Validation (1 week)

### SPIKE-1: Validate Claude API for CV Extraction

**Goal:** Determine if Claude API can reliably extract CV data before committing to full build

**Story Points:** 8 (research spike)
**Priority:** P0 (Blocks all other stories)
**Sprint:** Sprint 0
**Dependencies:** None

**Tasks:**

1. **Preparation (1 hour)**
   - [ ] Create Anthropic API account
   - [ ] Get API key
   - [ ] Set up test environment
   - [ ] Collect 10+ diverse CV samples:
     - PDF (text-based, 1-5 pages)
     - PDF (complex layout, multi-column)
     - DOCX (clean format)
     - DOCX (with tables)
     - CVs from different industries

2. **Prompt Engineering (2 hours)**
   - [ ] Draft extraction prompt template
   - [ ] Define desired JSON output structure
   - [ ] Test prompt with 3 sample CVs
   - [ ] Iterate until output quality acceptable

3. **Accuracy Testing (3 hours)**
   - [ ] Run extraction on all 10 CVs
   - [ ] Manually compare extracted vs actual data
   - [ ] Calculate accuracy per field type:
     - Name, email, phone (should be >95%)
     - Work experience (company, title, dates) (should be >85%)
     - Skills (should be >80%)
     - Education (should be >75%)
   - [ ] Document common failure patterns

4. **Performance Testing (1 hour)**
   - [ ] Measure extraction time for each CV
   - [ ] Calculate 95th percentile latency
   - [ ] Identify timeout risks

5. **Cost Analysis (1 hour)**
   - [ ] Calculate tokens used per CV
   - [ ] Calculate cost per extraction
   - [ ] Project monthly costs for 1, 100, 1000 users
   - [ ] Set budget recommendations

**Deliverable:** Spike Report

```markdown
# Sprint 0 Spike Report: Claude API Validation

## Results Summary
- **Accuracy:** X% average across all fields
- **Extraction Time:** X seconds (95th percentile)
- **Cost:** $X per extraction
- **Failure Rate:** X% (AI timeout, parse errors)

## Go/No-Go Recommendation
- [ ] GO: All criteria met (>80% accuracy, <30s time, <$0.15 cost)
- [ ] NO-GO: Critical criteria failed

## Next Steps if GO
- Proceed to Sprint 1
- Use documented prompt template
- Budget $X/month for AI costs

## Next Steps if NO-GO
- Consider alternatives (OpenAI GPT-4, manual only)
- Document why feature is not viable
```

**DoR:**
- [ ] API access approved
- [ ] Test CV samples collected
- [ ] Evaluation criteria defined

**DoD:**
- [ ] Spike report completed
- [ ] Go/no-go decision made
- [ ] Findings documented
- [ ] Prompt template ready (if GO)

---

## Epic 1: Modal Selection Flow

### US-1.1: Show Creation Method Modal

**As a** job seeker with an existing CV
**I want to** see a modal asking if I want to upload my CV or enter data manually
**So that** I can choose the fastest way to create my profile

**Story Points:** 3
**Priority:** P0 (Must-Have)
**Sprint:** Sprint 1
**Dependencies:** None

**Acceptance Criteria:**

1. **Modal Display**
   - [ ] Clicking "Create New Profile" shows modal (not direct navigation)
   - [ ] Modal title: "How would you like to create your profile?"
   - [ ] Two clear options displayed side-by-side

2. **Option A: Upload CV**
   - [ ] Primary button styling (blue, larger)
   - [ ] Label: "Upload CV"
   - [ ] Subtitle: "Let AI extract your information (PDF, DOCX)"
   - [ ] Icon: Upload icon
   - [ ] Click opens CVUploadModal

3. **Option B: Manual Entry**
   - [ ] Secondary button styling (gray, smaller)
   - [ ] Label: "Enter Manually"
   - [ ] Subtitle: "Fill out the form yourself"
   - [ ] Icon: Form/edit icon
   - [ ] Click navigates to `/profiles/new` (current behavior)

4. **Modal Behavior**
   - [ ] Can dismiss: X button, ESC key, click outside
   - [ ] Dismissing returns to profiles list
   - [ ] Modal centered on screen
   - [ ] Backdrop blur effect

5. **Mobile Responsive**
   - [ ] Stacks vertically on small screens
   - [ ] Buttons remain tappable (min 44Ã—44px)
   - [ ] Text remains readable

6. **Accessibility**
   - [ ] Modal has `role="dialog"` and `aria-modal="true"`
   - [ ] Title has unique id for `aria-labelledby`
   - [ ] Focus trapped in modal when open
   - [ ] First button receives focus on open
   - [ ] ESC key closes modal
   - [ ] Screen reader announces modal content

**Technical Notes:**
- **Component:** `ProfileCreationModal.vue`
- **Modify:** `ProfilesListView.vue` (line 79-81)
  - Change from: `router.push('/profiles/new')`
  - Change to: `showCreationModal = true`
- **State:** Add `showCreationModal` ref in ProfilesListView

**DoR Checklist:**
- [ ] Wireframe/mockup approved
- [ ] UX copy reviewed: "Upload CV" vs "Import from CV"?
- [ ] Icon selection decided
- [ ] Mobile behavior defined (stacked layout)

**DoD Checklist:**
- [ ] Unit test: Modal shows/hides correctly
- [ ] Unit test: Button clicks trigger correct actions
- [ ] Integration test: Navigation to manual form works
- [ ] Integration test: Opens upload modal correctly
- [ ] Mobile tested on iPhone, Android, tablet
- [ ] Keyboard navigation works (Tab, Enter, ESC)
- [ ] Screen reader tested (VoiceOver or NVDA)
- [ ] Code reviewed

---

## Epic 2: File Upload & Validation

### US-2.1: Upload CV File with Validation

**As a** job seeker
**I want to** upload my CV file (PDF or DOCX) with instant validation
**So that** I know my file is accepted before processing starts

**Story Points:** 5
**Priority:** P0 (Must-Have)
**Sprint:** Sprint 1
**Dependencies:** US-1.1 completed

**Acceptance Criteria:**

1. **File Selection**
   - [ ] File input accepts `.pdf` and `.docx` extensions only
   - [ ] Drag-and-drop zone visible
   - [ ] Click to browse file picker
   - [ ] File name displayed after selection
   - [ ] File size displayed (e.g., "2.3 MB")

2. **Client-Side Validation**
   - [ ] MIME type check: `application/pdf`, `application/vnd.openxmlformats-officedocument.wordprocessingml.document`
   - [ ] File size limit: 10MB maximum
   - [ ] Validation runs immediately after file selection
   - [ ] Invalid files show error before upload starts

3. **Upload Process**
   - [ ] "Upload & Continue" button enabled only when file valid
   - [ ] Progress bar shows upload percentage
   - [ ] Status text: "Uploading... X% complete"
   - [ ] Cannot change file during upload
   - [ ] "Cancel" button stops upload

4. **Upload Completion**
   - [ ] Success message: "CV uploaded successfully"
   - [ ] File stored in Supabase Storage (`cv-uploads` bucket)
   - [ ] Metadata saved in `cv_uploads` table
   - [ ] Transitions to extraction status screen

5. **Error Handling**
   - [ ] **Unsupported Format:** "Only PDF and DOCX files are supported"
   - [ ] **File Too Large:** "File size must be under 10MB (yours: X MB)"
   - [ ] **Upload Failed (Network):** "Upload failed. Please try again." + Retry button
   - [ ] **Storage Error:** "Unable to save file. Please try again later."
   - [ ] All errors show friendly messages (not technical codes)

6. **Remove/Retry**
   - [ ] "Remove File" button after selection (before upload)
   - [ ] "Try Again" button after upload failure
   - [ ] Removing file returns to file picker state

7. **Accessibility**
   - [ ] File input has `<label>` associated
   - [ ] Drag-and-drop zone has ARIA label
   - [ ] Upload progress announced to screen readers (aria-live="polite")
   - [ ] Error messages linked with `aria-describedby`
   - [ ] Keyboard-only upload works (Tab to button, Enter to click)

**Technical Notes:**
- **Component:** `CVUploadModal.vue`
- **Storage:** Supabase Storage bucket `cv-uploads`
- **Database:** `cv_uploads` table (migration needed)
- **Frontend Validation:**
  ```typescript
  function validateFile(file: File): { valid: boolean; error?: string } {
    if (!ALLOWED_MIME_TYPES.includes(file.type)) {
      return { valid: false, error: 'Only PDF and DOCX files supported' };
    }
    if (file.size > MAX_FILE_SIZE) {
      return { valid: false, error: `File too large (${(file.size/1024/1024).toFixed(1)}MB). Max 10MB` };
    }
    return { valid: true };
  }
  ```

**DoR Checklist:**
- [ ] File size limit confirmed (10MB)
- [ ] Error message copy reviewed
- [ ] Drag-and-drop library chosen (or native HTML5)
- [ ] Supabase Storage bucket created
- [ ] RLS policies defined for bucket
- [ ] cv_uploads table schema approved

**DoD Checklist:**
- [ ] Unit tests: File validation logic (valid/invalid cases)
- [ ] Integration test: Upload to Supabase Storage succeeds
- [ ] E2E test: Full upload flow (select â†’ validate â†’ upload â†’ success)
- [ ] Error handling tested (disconnect network, invalid file)
- [ ] File cleanup on modal close (no orphaned uploads)
- [ ] Performance: 10MB file uploads in <10 seconds
- [ ] Security: RLS policies prevent accessing others' files

---

## Epic 3: AI Extraction Backend

### US-3.1: Extract CV Data Using AI

**As a** developer
**I want to** extract structured profile data from uploaded CV files
**So that** the form can be pre-populated automatically

**Story Points:** 8
**Priority:** P0 (Must-Have)
**Sprint:** Sprint 2
**Dependencies:** US-2.1 completed, Sprint 0 spike GO decision

**Acceptance Criteria:**

1. **Edge Function Setup**
   - [ ] Create Edge Function: `cv-extract`
   - [ ] API endpoint: POST /functions/v1/cv-extract
   - [ ] Secured with Supabase authentication
   - [ ] Rate limiting: 5 requests per user per hour

2. **Text Extraction**
   - [ ] PDF text extraction working (using pdf-parse or similar)
   - [ ] DOCX text extraction working (using mammoth or similar)
   - [ ] Handles multi-column PDFs
   - [ ] Handles table-based layouts
   - [ ] Detects image-only PDFs (error message)

3. **AI Integration**
   - [ ] Claude 3.5 Sonnet API integration
   - [ ] API key stored in Edge Function secrets
   - [ ] Extraction prompt uses template from spike
   - [ ] Structured JSON output parsing

4. **Data Mapping**
   - [ ] Extracted data matches master_profiles schema
   - [ ] Work experiences array properly formatted
   - [ ] Skills array with categories
   - [ ] Dates normalized to YYYY-MM format
   - [ ] Email/phone validated

5. **Confidence Scoring**
   - [ ] Each field has confidence score (0.0-1.0)
   - [ ] Overall extraction confidence calculated
   - [ ] Fields <0.7 confidence flagged for review

6. **Error Handling**
   - [ ] AI API timeout (60s) â†’ Retry once â†’ Fail gracefully
   - [ ] Invalid PDF â†’ Clear error message
   - [ ] Malformed AI response â†’ Parse error handling
   - [ ] Network errors â†’ Retry with exponential backoff (3 max)

7. **Storage & Retrieval**
   - [ ] Extraction result saved in `cv_extraction_tasks` table
   - [ ] Status: pending â†’ processing â†’ completed/failed
   - [ ] Task ID returned to frontend
   - [ ] Results queryable by task ID

**Technical Notes:**

**Extraction Prompt Template:**
```
You are a CV extraction expert. Extract structured information from this CV.

Output JSON in this exact format:
{
  "full_name": "string",
  "email": "string",
  "phone_primary": "string (E.164 format if possible)",
  "location": "string (City, Country)",
  "professional_summary": "string (100-500 words)",
  "years_of_experience": number,
  "current_position": "string",
  "work_experiences": [
    {
      "company_name": "string",
      "position_title": "string",
      "location": "string",
      "start_date": "YYYY-MM",
      "end_date": "YYYY-MM or null if current",
      "is_current": boolean,
      "description": "string (responsibilities)"
    }
  ],
  "skills": [
    {
      "skill_name": "string",
      "category": "Frontend|Backend|Tools|Other",
      "proficiency_level": "Expert|Advanced|Intermediate|Beginner",
      "years_of_experience": number or null
    }
  ],
  "confidence_scores": {
    "full_name": 0.98,
    "email": 0.95,
    ...
  }
}

CV Text:
"""
{cv_text}
"""
```

**Edge Function Code Structure:**
```typescript
// supabase/functions/cv-extract/index.ts
import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';
import Anthropic from 'https://esm.sh/@anthropic-ai/sdk@0.9.1';

serve(async (req) => {
  const supabase = createClient(...);
  const anthropic = new Anthropic({ apiKey: Deno.env.get('ANTHROPIC_API_KEY') });

  // 1. Get file from storage
  // 2. Extract text (pdf-parse or mammoth)
  // 3. Call Claude API
  // 4. Parse and validate response
  // 5. Store in cv_extraction_tasks
  // 6. Return task_id
});
```

**DoR Checklist:**
- [ ] **Sprint 0 spike completed** with GO decision
- [ ] Extraction prompt template finalized
- [ ] Claude API account and key ready
- [ ] Edge Function deployment process understood
- [ ] cv_extraction_tasks table schema approved
- [ ] Error handling strategy defined
- [ ] Test CV dataset prepared (10+ files)

**DoD Checklist:**
- [ ] Unit tests: Prompt generation, response parsing
- [ ] Integration tests: Call real Claude API with test CVs
- [ ] Extraction accuracy >85% on test dataset
- [ ] Extraction time <30s (95th percentile)
- [ ] Error handling tested: timeout, API error, invalid PDF
- [ ] Cost per extraction <$0.15
- [ ] API key security verified (not exposed)
- [ ] Rate limiting tested (blocks after 5 uploads)
- [ ] Edge Function deployed to production

---

## Epic 4: Form Pre-population & Review

### US-4.1: Pre-fill Form with Extracted Data

**As a** job seeker
**I want to** see my CV data pre-filled in the profile form
**So that** I can review and correct any extraction errors before saving

**Story Points:** 5
**Priority:** P0 (Must-Have)
**Sprint:** Sprint 2
**Dependencies:** US-3.1 completed

**Acceptance Criteria:**

1. **Status Polling**
   - [ ] After upload, show "Analyzing your CV..." with spinner
   - [ ] Poll extraction status every 2 seconds
   - [ ] Show progress indicator (if available)
   - [ ] Status messages: "Processing...", "Extracting work experience...", etc.
   - [ ] Maximum wait time: 60 seconds â†’ timeout error

2. **Extraction Completion**
   - [ ] On completion, navigate to ProfileForm with data
   - [ ] All extracted fields pre-populated
   - [ ] "Extracted from CV" badge shown at top
   - [ ] Overall confidence score displayed (e.g., "Confidence: 92%")

3. **Confidence Indicators**
   - [ ] High confidence (>0.9): Green checkmark icon
   - [ ] Medium confidence (0.7-0.9): Yellow warning icon
   - [ ] Low confidence (<0.7): Red warning icon + "Please review"
   - [ ] Tooltip shows confidence percentage on hover

4. **Form Population**
   - [ ] Basic info section pre-filled (name, email, phone, location)
   - [ ] Professional summary pre-filled
   - [ ] Work experiences array populated
   - [ ] Skills array populated with categories
   - [ ] Education section populated (if extracted)

5. **Editable Fields**
   - [ ] All fields remain editable (no read-only)
   - [ ] User can add/remove work experiences
   - [ ] User can add/remove skills
   - [ ] Changes not saved until "Submit" clicked

6. **Extraction Metadata**
   - [ ] Store extraction source in database: `extraction_method: 'ai'`
   - [ ] Store confidence scores: `extraction_confidence_score: 0.92`
   - [ ] Store extraction date for tracking

7. **Partial Extraction Handling**
   - [ ] If some fields missing, show: "We couldn't extract [field], please add manually"
   - [ ] Missing sections shown as empty (user adds manually)
   - [ ] Partial extraction still useful (don't discard)

8. **Discard Option**
   - [ ] "Start Over" button visible
   - [ ] Clicking shows confirmation: "Discard extracted data?"
   - [ ] Confirmation â†’ Clear form â†’ Manual entry mode

**Technical Notes:**

**Frontend Component Modifications:**
```typescript
// ProfileCreateView.vue
<template>
  <div class="profile-create-view">
    <!-- Show badge if data from CV extraction -->
    <div v-if="isFromExtraction" class="extraction-badge">
      <span class="icon">âœ¨</span>
      Extracted from CV (Confidence: {{ confidenceScore }}%)
      <button @click="handleStartOver">Start Over</button>
    </div>

    <ProfileForm
      :is-editing="false"
      :initial-data="extractedData"
      :confidence-scores="confidenceScores"
    />
  </div>
</template>

<script setup lang="ts">
import { onMounted } from 'vue';
import { useRoute } from 'vue-router';

const route = useRoute();
const isFromExtraction = ref(false);
const extractedData = ref(null);
const confidenceScores = ref({});

onMounted(async () => {
  const taskId = route.query.task_id as string;
  if (taskId) {
    // Poll for extraction result
    const result = await pollExtractionStatus(taskId);
    if (result.status === 'completed') {
      isFromExtraction.value = true;
      extractedData.value = result.extracted_data;
      confidenceScores.value = result.confidence_scores;
    }
  }
});
</script>
```

**Polling Logic:**
```typescript
// composables/useCVExtraction.ts
export function useCVExtraction() {
  async function pollExtractionStatus(taskId: string) {
    const maxAttempts = 30; // 60 seconds (2s intervals)
    let attempts = 0;

    while (attempts < maxAttempts) {
      const { data } = await supabase.functions.invoke(`cv-extraction-status/${taskId}`);

      if (data.status === 'completed' || data.status === 'failed') {
        return data;
      }

      await new Promise(resolve => setTimeout(resolve, 2000)); // Wait 2s
      attempts++;
    }

    throw new Error('Extraction timeout after 60 seconds');
  }

  return { pollExtractionStatus };
}
```

**DoR Checklist:**
- [ ] Polling strategy defined (interval, timeout)
- [ ] Confidence score UI design approved
- [ ] Partial extraction handling strategy defined
- [ ] ProfileForm accepts `initialData` prop (implementation ready)

**DoD Checklist:**
- [ ] Unit test: Polling stops on completion
- [ ] Unit test: Polling times out correctly
- [ ] Integration test: Extracted data populates form
- [ ] E2E test: Upload â†’ extract â†’ pre-filled form â†’ save
- [ ] Tested with low confidence data (shows warnings)
- [ ] Tested with partial extraction (missing sections)
- [ ] "Start Over" button clears form correctly
- [ ] No memory leaks from polling intervals

---

## Epic 5: Quality & Polish (Post-MVP)

### US-5.1: User Rates Extraction Quality

**As a** job seeker
**I want to** provide feedback on extraction accuracy
**So that** the system can improve over time

**Story Points:** 3
**Priority:** P1 (Should-Have, Post-MVP)
**Sprint:** Sprint 3
**Dependencies:** US-4.1 completed

**Acceptance Criteria:**

1. **Feedback Prompt**
   - [ ] After saving profile, show: "How accurate was the extraction?"
   - [ ] Simple rating: ðŸ˜ž Poor | ðŸ˜ OK | ðŸ˜Š Good
   - [ ] Optional text field: "What could be better?"
   - [ ] Can skip feedback (not mandatory)

2. **Feedback Storage**
   - [ ] Store in `cv_extraction_feedback` table
   - [ ] Link to profile_id and task_id
   - [ ] Timestamp recorded
   - [ ] Anonymous (no PII in feedback text)

3. **Analytics Dashboard**
   - [ ] Simple dashboard showing:
     - Average rating over time
     - Common issues (from text feedback)
     - Accuracy trends

**Technical Notes:**
```sql
CREATE TABLE cv_extraction_feedback (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  task_id UUID REFERENCES cv_extraction_tasks(id),
  profile_id UUID REFERENCES master_profiles(id),
  rating INTEGER CHECK (rating IN (1, 2, 3)), -- Poor, OK, Good
  feedback_text TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

**DoR Checklist:**
- [ ] Feedback UI design approved
- [ ] Analytics requirements defined

**DoD Checklist:**
- [ ] Feedback stored successfully
- [ ] Analytics query works
- [ ] Can skip feedback without breaking flow

---

## Sprint Planning

### Sprint 0: Spike (1 week)
**Goal:** Validate Claude API feasibility

**Stories:**
- SPIKE-1: Claude API Validation (8 points)

**Output:** Go/no-go decision

**Risk Mitigation:**
- Test with diverse CV formats
- Measure real-world accuracy
- Document failure patterns

---

### Sprint 1: Upload UI (1 week - 8 points)
**Goal:** Users can upload CV files

**Stories:**
- US-1.1: Modal Selection Flow (3 points)
- US-2.1: File Upload & Validation (5 points)

**Sprint Goal:** By end of sprint, users can upload files and see confirmation

**Risks:**
- Supabase Storage configuration complexity
- RLS policies for file access
- File validation edge cases

---

### Sprint 2: AI Extraction (2 weeks - 13 points)
**Goal:** Working extraction flow

**Stories:**
- US-3.1: AI Extraction Backend (8 points)
- US-4.1: Form Pre-population (5 points)

**Sprint Goal:** Users can upload â†’ extract â†’ review â†’ save profile

**Risks:**
- AI extraction accuracy below target
- Extraction timeout for large CVs
- Polling implementation complexity
- Cost overruns on API usage

---

### Sprint 3: Polish (3-5 days - 3 points)
**Goal:** Production-ready

**Stories:**
- US-5.1: Quality Feedback (3 points)
- Bug fixes from Sprint 2 testing
- Documentation polish

**Sprint Goal:** Feature is production-ready with quality monitoring

**Risks:**
- Unexpected bugs from user testing
- Performance issues at scale

---

## Story Dependencies Graph

```
Sprint 0:
SPIKE-1 (Claude API Validation)
    â†“ (GO decision)

Sprint 1:
US-1.1 (Modal Flow)
    â†“
US-2.1 (File Upload)
    â†“

Sprint 2:
US-3.1 (AI Extraction)
    â†“
US-4.1 (Form Pre-fill)
    â†“

Sprint 3:
US-5.1 (Quality Feedback)
```

---

## Acceptance Testing Checklist

### Before Sprint Completion

**Sprint 1 Testing:**
- [ ] Can upload valid PDF successfully
- [ ] Can upload valid DOCX successfully
- [ ] Invalid file shows error (TXT, EXE, etc.)
- [ ] File >10MB shows error
- [ ] Upload progress bar works
- [ ] Network error shows retry option
- [ ] RLS: Cannot access other users' uploads

**Sprint 2 Testing:**
- [ ] Extraction completes in <30 seconds
- [ ] Extracted data matches CV content
- [ ] All required fields populated
- [ ] Work experience dates correct
- [ ] Skills categorized correctly
- [ ] Low confidence fields highlighted
- [ ] Can edit extracted data before save
- [ ] Partial extraction handled gracefully

**Sprint 3 Testing:**
- [ ] Can provide feedback rating
- [ ] Feedback stored correctly
- [ ] Analytics dashboard shows data
- [ ] Feature works end-to-end 10+ times without errors

---

## Production Readiness Checklist

**Before Production Launch:**
- [ ] All user stories completed (US-1.1 through US-5.1)
- [ ] All DoD criteria met for each story
- [ ] Security review passed (file upload, API keys)
- [ ] Performance testing passed (100+ concurrent users simulated)
- [ ] Cost monitoring configured (budget alerts)
- [ ] Rollback plan documented and tested
- [ ] User guide created with screenshots
- [ ] Support documentation prepared
- [ ] Feature flag configured (can disable if issues)
- [ ] Analytics tracking implemented

---

**Document Version:** 1.0
**Last Updated:** October 6, 2025
**Next Review:** After Sprint 0 spike completion
